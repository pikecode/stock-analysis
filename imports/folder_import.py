#!/usr/bin/env python
"""
æ–‡ä»¶å¤¹æ‰¹é‡å¯¼å…¥è„šæœ¬ - è‡ªåŠ¨æ‰«æå¹¶å¯¼å…¥æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰TXTæ–‡ä»¶

Usage:
    python imports/folder_import.py <folder_path> [options]

Examples:
    # å¯¼å…¥æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰TXTæ–‡ä»¶
    python imports/folder_import.py test-data

    # åªå¯¼å…¥EEEæŒ‡æ ‡
    python imports/folder_import.py test-data --metric-code EEE

    # åªå¯¼å…¥ç‰¹å®šæ—¥æœŸèŒƒå›´
    python imports/folder_import.py test-data --start-date 2025-11-18 --end-date 2025-11-21

    # å¹¶è¡Œå¤„ç†ï¼ˆ4ä¸ªè¿›ç¨‹ï¼‰
    python imports/folder_import.py test-data --parallel 4

    # è·³è¿‡å·²å¯¼å…¥çš„æ–‡ä»¶
    python imports/folder_import.py test-data --skip-existing
"""

import sys
import os
from pathlib import Path
from datetime import datetime, date
from typing import List, Dict, Optional, Tuple
import argparse
import re
from dataclasses import dataclass
from multiprocessing import Pool, cpu_count
import logging
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
backend_path = os.path.join(project_root, 'backend')
sys.path.insert(0, backend_path)

from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine
from app.core.config import settings
from app.services.import_service import ImportService
from app.models.stock import ImportBatch

# åˆ›å»ºæ•°æ®åº“ä¼šè¯
engine = create_engine(settings.DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class FileInfo:
    """æ–‡ä»¶ä¿¡æ¯"""
    file_path: str
    file_name: str
    metric_code: str
    data_date: date
    file_size: int

    def __str__(self):
        return f"{self.metric_code}_{self.data_date.strftime('%Y-%m-%d')}"


class FolderImporter:
    """æ–‡ä»¶å¤¹æ‰¹é‡å¯¼å…¥å™¨"""

    # æ”¯æŒçš„æ–‡ä»¶åæ ¼å¼
    # EEE_2025-11-18.txt
    # TTV_20251118.txt
    # EEE_2025_11_18.txt
    FILE_PATTERNS = [
        r'([A-Z]+)_(\d{4}-\d{2}-\d{2})\.txt$',  # METRIC_YYYY-MM-DD.txt
        r'([A-Z]+)_(\d{8})\.txt$',               # METRIC_YYYYMMDD.txt
        r'([A-Z]+)_(\d{4})_(\d{2})_(\d{2})\.txt$',  # METRIC_YYYY_MM_DD.txt
    ]

    def __init__(
        self,
        folder_path: str,
        metric_code: Optional[str] = None,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        parallel: int = 1,
        skip_existing: bool = False
    ):
        self.folder_path = Path(folder_path)
        self.metric_code = metric_code.upper() if metric_code else None
        self.start_date = start_date
        self.end_date = end_date
        self.parallel = max(1, min(parallel, cpu_count()))
        self.skip_existing = skip_existing

        if not self.folder_path.exists():
            raise ValueError(f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")

    def parse_filename(self, file_name: str) -> Optional[Tuple[str, date]]:
        """ä»æ–‡ä»¶åè§£ææŒ‡æ ‡ä»£ç å’Œæ—¥æœŸ"""
        for pattern in self.FILE_PATTERNS:
            match = re.match(pattern, file_name)
            if match:
                metric = match.group(1).upper()

                # è§£ææ—¥æœŸ
                if len(match.groups()) == 2:
                    date_str = match.group(2)
                    if len(date_str) == 8:  # YYYYMMDD
                        data_date = datetime.strptime(date_str, '%Y%m%d').date()
                    else:  # YYYY-MM-DD
                        data_date = datetime.strptime(date_str, '%Y-%m-%d').date()
                else:  # YYYY_MM_DD
                    year, month, day = match.group(2), match.group(3), match.group(4)
                    data_date = date(int(year), int(month), int(day))

                return metric, data_date

        return None

    def scan_folder(self) -> List[FileInfo]:
        """æ‰«ææ–‡ä»¶å¤¹ï¼Œè·å–æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„TXTæ–‡ä»¶"""
        logger.info(f"æ‰«ææ–‡ä»¶å¤¹: {self.folder_path}")

        files = []
        skipped = 0

        for file_path in self.folder_path.glob("*.txt"):
            # è·³è¿‡æ··åˆæ—¥æœŸæ–‡ä»¶
            if 'mixed' in file_path.name.lower():
                continue

            # è§£ææ–‡ä»¶å
            parsed = self.parse_filename(file_path.name)
            if not parsed:
                logger.warning(f"æ— æ³•è§£ææ–‡ä»¶å: {file_path.name}")
                skipped += 1
                continue

            metric_code, data_date = parsed

            # è¿‡æ»¤æŒ‡æ ‡
            if self.metric_code and metric_code != self.metric_code:
                continue

            # è¿‡æ»¤æ—¥æœŸèŒƒå›´
            date_str = data_date.strftime('%Y-%m-%d')
            if self.start_date and date_str < self.start_date:
                continue
            if self.end_date and date_str > self.end_date:
                continue

            # åˆ›å»ºæ–‡ä»¶ä¿¡æ¯
            file_info = FileInfo(
                file_path=str(file_path),
                file_name=file_path.name,
                metric_code=metric_code,
                data_date=data_date,
                file_size=file_path.stat().st_size
            )
            files.append(file_info)

        logger.info(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ï¼Œè·³è¿‡ {skipped} ä¸ª")
        return sorted(files, key=lambda x: (x.metric_code, x.data_date))

    def check_existing(self, file_info: FileInfo) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å¯¼å…¥"""
        db = SessionLocal()
        try:
            # æŸ¥æ‰¾åŒåæ–‡ä»¶çš„æˆåŠŸå¯¼å…¥è®°å½•
            existing = db.query(ImportBatch).filter(
                ImportBatch.file_name == file_info.file_name,
                ImportBatch.status == 'completed',
                ImportBatch.error_rows == 0
            ).first()
            return existing is not None
        finally:
            db.close()

    def import_single_file(self, file_info: FileInfo) -> Tuple[str, bool, str]:
        """å¯¼å…¥å•ä¸ªæ–‡ä»¶"""
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_info.file_path, 'rb') as f:
                file_content = f.read()

            # åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯
            db = SessionLocal()

            try:
                # è·å–å¯¼å…¥æœåŠ¡
                import_service = ImportService(db)

                # è·å–æˆ–åˆ›å»ºæŒ‡æ ‡ç±»å‹
                metric_type = import_service.get_metric_type(file_info.metric_code)
                if not metric_type:
                    from app.models.stock import MetricType
                    metric_type = MetricType(
                        code=file_info.metric_code,
                        name=file_info.metric_code,
                        description=f"{file_info.metric_code} äº¤æ˜“æ•°æ®"
                    )
                    db.add(metric_type)
                    db.commit()
                    db.refresh(metric_type)

                # åˆ›å»ºå¯¼å…¥æ‰¹æ¬¡
                batch = import_service.create_batch(
                    file_name=file_info.file_name,
                    file_type='TXT',
                    file_size=file_info.file_size,
                    file_content=file_content,
                    metric_type_id=metric_type.id,
                    data_date=file_info.data_date,
                    user_id=1
                )

                # ä¿å­˜batch_idï¼ˆåœ¨sessionå…³é—­å‰ï¼‰
                batch_id = batch.id

                # è°ƒç”¨ç»Ÿä¸€å¯¼å…¥æ–¹æ³•
                success_count, error_count = import_service.import_txt_file(
                    batch_id=batch_id,
                    file_content=file_content,
                    metric_type_id=metric_type.id,
                    data_date=file_info.data_date
                )

                db.close()

                return (
                    str(file_info),
                    True,
                    f"æˆåŠŸ: {success_count}æ¡, æ‰¹æ¬¡ID: {batch_id}"
                )

            except Exception as e:
                db.close()
                raise e

        except Exception as e:
            logger.error(f"å¯¼å…¥å¤±è´¥ {file_info}: {str(e)}")
            return str(file_info), False, f"å¤±è´¥: {str(e)}"

    def import_folder(self):
        """æ‰§è¡Œæ–‡ä»¶å¤¹æ‰¹é‡å¯¼å…¥"""

        # æ‰«ææ–‡ä»¶
        files = self.scan_folder()

        if not files:
            logger.info("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶")
            return

        # æ£€æŸ¥å·²å­˜åœ¨çš„æ–‡ä»¶
        if self.skip_existing:
            original_count = len(files)
            files = [f for f in files if not self.check_existing(f)]
            skipped_count = original_count - len(files)
            if skipped_count > 0:
                logger.info(f"è·³è¿‡å·²å¯¼å…¥çš„æ–‡ä»¶: {skipped_count} ä¸ª")

        if not files:
            logger.info("æ‰€æœ‰æ–‡ä»¶éƒ½å·²å¯¼å…¥")
            return

        # æ˜¾ç¤ºç»Ÿè®¡
        print("\n" + "="*60)
        print("ğŸ“Š æ–‡ä»¶å¤¹å¯¼å…¥ç»Ÿè®¡:")
        print(f"  æ–‡ä»¶å¤¹: {self.folder_path}")
        print(f"  å¾…å¯¼å…¥æ–‡ä»¶æ•°: {len(files)}")

        # æŒ‰æŒ‡æ ‡ç»Ÿè®¡
        metric_stats = {}
        for f in files:
            metric_stats[f.metric_code] = metric_stats.get(f.metric_code, 0) + 1

        print(f"  æŒ‡æ ‡åˆ†å¸ƒ:")
        for metric, count in sorted(metric_stats.items()):
            print(f"    - {metric}: {count} ä¸ªæ–‡ä»¶")

        print(f"  å¹¶è¡Œè¿›ç¨‹æ•°: {self.parallel}")
        print("="*60 + "\n")

        # æ‰§è¡Œå¯¼å…¥
        start_time = datetime.now()
        success_count = 0
        failed_count = 0
        results = []

        with tqdm(total=len(files), desc="å¯¼å…¥è¿›åº¦") as pbar:
            if self.parallel == 1:
                # å•è¿›ç¨‹
                for file_info in files:
                    name, success, msg = self.import_single_file(file_info)
                    results.append((name, success, msg))

                    if success:
                        success_count += 1
                    else:
                        failed_count += 1

                    pbar.set_postfix_str(f"{name}: {msg[:30]}...")
                    pbar.update(1)
            else:
                # å¤šè¿›ç¨‹
                with Pool(processes=self.parallel) as pool:
                    for name, success, msg in pool.imap_unordered(
                        self.import_single_file, files
                    ):
                        results.append((name, success, msg))

                        if success:
                            success_count += 1
                        else:
                            failed_count += 1

                        pbar.set_postfix_str(f"{name}: {msg[:30]}...")
                        pbar.update(1)

        end_time = datetime.now()

        # æ˜¾ç¤ºç»“æœ
        print("\n" + "="*60)
        print("âœ… å¯¼å…¥å®Œæˆ:")
        print(f"  æˆåŠŸ: {success_count}/{len(files)}")
        print(f"  å¤±è´¥: {failed_count}")
        print(f"  è€—æ—¶: {end_time - start_time}")

        if failed_count > 0:
            print("\nâŒ å¤±è´¥çš„æ–‡ä»¶:")
            for name, success, msg in results:
                if not success:
                    print(f"    - {name}: {msg}")

        print("="*60 + "\n")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='æ‰¹é‡å¯¼å…¥æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰TXTæ–‡ä»¶'
    )

    parser.add_argument('folder', help='æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--metric-code', help='åªå¯¼å…¥æŒ‡å®šæŒ‡æ ‡ï¼ˆå¦‚EEEï¼‰')
    parser.add_argument('--start-date', help='å¼€å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰')
    parser.add_argument('--end-date', help='ç»“æŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰')
    parser.add_argument('--parallel', type=int, default=1, help='å¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤1ï¼‰')
    parser.add_argument('--skip-existing', action='store_true', help='è·³è¿‡å·²å¯¼å…¥çš„æ–‡ä»¶')

    args = parser.parse_args()

    # åˆ›å»ºå¯¼å…¥å™¨
    importer = FolderImporter(
        folder_path=args.folder,
        metric_code=args.metric_code,
        start_date=args.start_date,
        end_date=args.end_date,
        parallel=args.parallel,
        skip_existing=args.skip_existing
    )

    try:
        # æ‰§è¡Œå¯¼å…¥
        importer.import_folder()
    except KeyboardInterrupt:
        print("\nâš ï¸ å¯¼å…¥è¢«ä¸­æ–­")
    except Exception as e:
        logger.error(f"å¯¼å…¥å¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == '__main__':
    main()
